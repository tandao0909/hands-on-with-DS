{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:45:48.783461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: *Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized `Example` protobuf with two features: the serialized image (use `tf.io.serialize_tensor()` to serialize each image), and the label.*\n",
    "\n",
    "**Note**: For large images, you could use `tf.io.encode_jpeg()` instead. This could save a lot of space, but it would lose a bit of image quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = (\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    ")\n",
    "X_train, y_train = X_train_full[5000:], y_train_full[5000:]\n",
    "X_valid, y_valid = X_train_full[:5000], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:45:50.692618: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_set = train_set.shuffle(len(X_train), seed=42)\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, Int64List, Features, Feature, Example\n",
    "\n",
    "\n",
    "def create_example(image, label) -> Example:\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000T\\301\\206Wi\\\\\\217\\203\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\350\\343\\325\\363\\377\\377\\356\\351\\362\\305\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\262\\366\\276\\316\\353\\340\\351\\362\\321\\277\\337\\234\\027\\000\\000\\002\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000e\\327\\320\\320\\312\\363\\361\\357\\366\\326\\330\\327\\327\\333c\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000B\\334\\312\\327\\351\\327\\337\\372\\373\\357\\335\\324\\312\\311\\312\\316\\007\\000\\002\\000\\000\\000\\000\\000\\000\\000\\000\\000\\276\\314\\301\\315\\311\\315\\326\\330\\335\\312\\310\\310\\313\\312\\302\\326W\\000\\002\\000\\000\\000\\000\\000\\000\\000\\000Z\\333\\305\\300\\271\\300\\301\\277\\276\\275\\276\\262\\247\\271\\274\\301\\323\\251\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\243\\330\\306\\303\\304\\304\\301\\300\\305\\311\\306\\262\\236\\270\\304\\316\\327\\300\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\255\\326\\307\\332\\306\\304\\274\\303\\303\\307\\303\\304\\310\\302\\340\\331\\312\\330-\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\327\\310\\344\\315\\300\\306\\306\\310\\310\\311\\277\\305\\271\\370\\341\\315\\336s\\000\\000\\000\\000\\000\\000\\000\\000\\000\\312\\335\\307\\356\\354\\303\\314\\302\\310\\312\\311\\300\\311\\302\\347\\350\\323\\335\\235\\000\\000\\000\\000\\000\\000\\000\\000\\000\\315\\336\\326\\356\\327\\315\\310\\301\\306\\314\\313\\303\\306\\307\\347\\363\\313\\337\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\376\\330\\342\\351\\314\\322\\303\\306\\307\\313\\312\\301\\302\\330\\252\\360\\322\\331\\355\\000\\000\\000\\000\\000\\000\\000\\000\\000\\377\\343\\343\\342\\314\\312\\304\\310\\302\\317\\311\\300\\274\\355s\\264\\341\\340\\324\\000\\000\\000\\000\\000\\000\\000\\000\\\"\\343\\350\\366\\341\\311\\306\\307\\310\\304\\324\\306\\301\\303\\351\\177\\264\\347\\350\\321\\027\\000\\000\\000\\000\\000\\000\\000Q\\335\\353\\365\\253\\313\\306\\312\\307\\305\\325\\310\\300\\303\\336\\215\\275\\366\\341\\325H\\000\\000\\000\\000\\000\\000\\000l\\331\\353\\377k\\322\\306\\314\\304\\305\\330\\312\\275\\305\\340\\215\\254\\377\\326\\360[\\000\\000\\000\\000\\000\\000\\000\\204\\323\\355\\377=\\343\\302\\315\\302\\311\\327\\313\\276\\312\\341\\240\\202\\376\\322\\363a\\000\\000\\000\\000\\000\\000\\000\\222\\317\\360\\331;\\365\\304\\314\\312\\311\\322\\321\\301\\310\\324\\312a\\377\\330\\357m\\000\\000\\000\\000\\000\\000\\000\\244\\316\\360\\267c\\363\\307\\311\\306\\303\\323\\320\\305\\305\\311\\341D\\371\\344\\345z\\000\\000\\000\\000\\000\\000\\000\\247\\313\\377my\\360\\306\\304\\305\\312\\316\\317\\313\\307\\302\\342w\\364\\351\\340\\210\\000\\000\\000\\000\\000\\000\\000\\253\\307\\377>\\224\\357\\301\\310\\312\\313\\317\\307\\320\\312\\310\\327\\230\\362\\336\\337\\223\\000\\000\\000\\000\\000\\000\\000\\255\\316\\377P\\265\\332\\311\\311\\313\\315\\321\\304\\316\\306\\310\\321\\246\\352\\332\\344\\230\\000\\000\\000\\000\\000\\000\\000\\247\\322\\373Z\\273\\333\\315\\311\\316\\313\\320\\306\\315\\310\\317\\323\\242\\326\\332\\353\\233\\000\\000\\000\\000\\000\\000\\000\\243\\316\\373^\\275\\325\\313\\312\\315\\311\\323\\305\\312\\307\\313\\337\\240\\270\\347\\345\\237\\000\\000\\000\\000\\000\\000\\000\\242\\314\\346h\\273\\315\\311\\304\\303\\277\\323\\300\\277\\304\\303\\327\\241\\245\\351\\322\\242\\000\\000\\000\\000\\000\\000\\000\\266\\342\\366\\241\\364\\356\\361\\362\\355\\354\\356\\345\\343\\341\\342\\345\\316\\235\\354\\321\\274\\000\\000\\000\\000\\000\\000\\000\\032v\\231Mdxu}\\210\\221\\235\\233\\235\\231\\235\\235\\224C\\340\\320~\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 4\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:45:50.781480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [55000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-03-14 20:45:50.781653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [55000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Test create_example() function\n",
    "\n",
    "for image, label in train_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function does:\n",
    "- Save a given dataset to a set of TFRecord files. The examples are written in a simple round-robin fashion.\n",
    "- To do this, we enumerate over the dataset using the `enumerate()` method.\n",
    "- We compute `index % n_shards` to decide which file to write to.\n",
    "\n",
    "We use the standard `contextlib.ExitStack` class to make sure all writers are properly closed whether or not an I/O error occurs during writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "\n",
    "def write_tfrecord(name, dataset, n_shards=10):\n",
    "    paths = [\n",
    "        \"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "        for index in range(n_shards)\n",
    "    ]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:45:50.904262: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:45:50.918176: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [55000]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-03-14 20:45:50.918574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype uint8 and shape [55000,28,28]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-03-14 20:46:02.845371: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-03-14 20:46:02.847918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [5000]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-03-14 20:46:03.739445: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-03-14 20:46:03.742599: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [10000]\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    }
   ],
   "source": [
    "train_filepaths = write_tfrecord(name=\"my_fashion_mnist.train\", dataset=train_set)\n",
    "valid_filepaths = write_tfrecord(name=\"my_fashion_mnist.valid\", dataset=valid_set)\n",
    "test_filepaths = write_tfrecord(name=\"my_fashion_mnist.test\", dataset=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: *Then use tf.data to create an efficient dataset for each set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "\n",
    "def mnist(\n",
    "    filepaths,\n",
    "    n_read_threads=5,\n",
    "    shuffle_buffer_size=None,\n",
    "    n_parse_threads=None,\n",
    "    seed=42,\n",
    "    batch_size=32,\n",
    "    cache=True,\n",
    "):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
    "\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist(train_filepaths, shuffle_buffer_size=60_000)\n",
    "valid_set = mnist(valid_filepaths)\n",
    "test_set = mnist(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:46:05.734674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-14 20:46:05.735252: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAB9CAYAAADdsHu2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcE0lEQVR4nO2de5CVdRnHn1UxLyQsLCALwirQLigiocIo0qqVhJLQlI06kmKZihckrwm0oOE6zk5MYiVpgxNqTlARhFkjtyhAggVCSwEBV0Rwl3XdRexKfzT79Dmv53c4wO6+5/L9zDjz3cN53/M77+38/D6/53kKDh48eNCEEEIIkdccE/cAhBBCCBE/mhAIIYQQQhMCIYQQQmhCIIQQQgjThEAIIYQQpgmBEEIIIUwTAiGEEEKYJgRCCCGEME0IhBBCCGE5MiFobGy0e++91z7/+c9bly5drKCgwCoqKuIeljCz6upqGzNmjBUXF9tJJ51kZWVlNn36dPvwww/jHlpes2zZMisoKEj63+rVq+MeXl6zZMkSGz9+vJWVldnJJ59sPXr0sCuvvNLWrVsX99BEhKeeesoKCgqsffv2cQ+lRTgu7gG0BHV1dTZ79mwbNGiQjRkzxp566qm4hyTM7LXXXrMLLrjASktLbebMmVZUVGQrVqyw6dOn27p162zBggVxDzHvmTFjhl188cUJr5111lkxjUaYmf3whz+0uro6u/POO23AgAH23nvvWVVVlQ0bNsxeeuklu+SSS+IeojCzXbt22d13323FxcXW0NAQ93BahJyYEPTu3dvq6+utoKDAamtrNSHIEJ577jn76KOPbP78+danTx8zM7vkkkts9+7dNnv2bKuvr7fCwsKYR5nf9OvXz4YNGxb3MAR44oknrGvXrgmvjRw50vr27WszZszQhCBDuPnmm23EiBHWqVMnmzdvXtzDaRFyImTQbHWKzKJdu3ZmZtahQ4eE1zt27GjHHHOMHX/88XEMS4iMJjoZMDNr3769DRgwwGpqamIYkYgyd+5cW758uf3gBz+IeygtSk5MCERm8rWvfc06duxot9xyi7355pvW2NhoixYtsieffNImTJhgJ598ctxDzHsmTJhgxx13nJ1yyil22WWX2cqVK+MekkhCQ0ODrV+/3s4888y4h5L37N271yZOnGiVlZXWs2fPuIfTouREyEBkJiUlJbZq1SobO3ashwzMzO644w6bOXNmfAMT1qFDB7vzzjutvLzcOnfubFu3brXHHnvMysvL7Te/+Y1ddtllcQ9RgAkTJtj+/fvtwQcfjHsoec+tt95qpaWldsstt8Q9lBZHEwLRauzYscNGjx5t3bp1s3nz5lmXLl1szZo19vDDD1tTU5M9/fTTcQ8xbxk8eLANHjzY/77ooots7NixNnDgQLv33ns1IcggpkyZYs8++6w9/vjjNmTIkLiHk9fMnz/fFi5caNXV1TkZptaEQLQa999/v33wwQe2YcMGDw+MGDHCioqKbPz48TZu3Dj7zGc+E/MoRTMdO3a0K664wn70ox/ZgQMH7MQTT4x7SHnPtGnT7OGHH7bvfve7dtttt8U9nLymqanJJkyYYLfffrsVFxfb+++/b2Zm//jHP8zM7P3337d27dpldShUawhEq7FhwwYbMGDAx26Q8847z8zMNm/eHMewRAoOHjxoZpaT//eTbUybNs0qKiqsoqLCvv3tb8c9nLyntrbW9uzZY1VVVVZYWOj/Pf/887Z//34rLCy0a6+9Nu5hHhVyCESrUVxcbJs3b7ampqaEwh2rVq0yM8u5BTnZTn19vS1atMjOOeccO+GEE+IeTl7z0EMPWUVFhU2ePNm+853vxD0cYWannnqqLV269GOvV1ZW2vLly+3FF1+0oqKiGEbWcuTMhODFF1+0/fv3W2Njo5n9ryhOc27oqFGj7KSTTopzeHnJxIkTbcyYMfa5z33O7rrrLisqKrLVq1fbI488YgMGDLAvfOELcQ8xb7nmmmusV69edu6551pRUZFt2bLFqqqqbM+ePTZnzpy4h5fXVFVV2dSpU23kyJF2+eWXf6xypOpGxMMJJ5xg5eXlH3t9zpw5duyxxyb9t2yj4GCzR5jllJSU2M6dO5P+2/bt262kpKRtByTMzGzp0qVWWVlpmzZtsoaGBjvttNNs9OjR9sADD1jnzp3jHl7eUllZaS+88IJt377dmpqarFOnTjZ8+HB74IEHPKQj4qG8vNyWL18e/PcceWTnDNdff73NmzfPmpqa4h7KUZMzEwIhhBBCHDlaVCiEEEIITQiEEEIIoQmBEEIIIUwTAiGEEEKYJgRCCCGEME0IhBBCCGFZUpho1qxZrtu1a+eatdZZCe/DDz90/frrr7s+/vjjXTNntLkmtZnZ1Vdf7ToXCk20Nv/5z39cH3NM8vkle4Y3NDS4Hj16tOuzzjrL9b/+9S/Xxx2XFZeoEGmzePFi1+vXr3f95ptvuubzqblWvlni/cPn38CBA10/+uijST/33//+t+tjjz32cIedMzDTPp0S3fwNee+995Luh4XvWF+FlQv5G3U042lN5BAIIYQQQhMCIYQQQmRwpcK9e/e6Hjp0qOsePXq4pn1GO+ajjz5y/cEHH7imlUP7bPfu3a7LyspcL1my5IjGnk+EQgY33XST6zvuuMM1QwMMySxbtizp/jPJThMiSqrwFp9hF154oet9+/YdcnuGPdloimFP2tTvvvuua/YI+cUvfuE6X++l6E9c6LvffPPNrhm+4THv1q2ba55fhmDq6+tds9NrbW2ta54XNnnj71J0v22BHAIhhBBCaEIghBBCiAzOMtixY4drhgO6du3qulOnTq7//ve/u/7kJz+ZVP/zn/90XVxc7JoW3qmnnnoUo84PQmECHsdt27a5ZpiATJo0yfXUqVNdT58+3TXPGTNM8snyFJkFLWjeC6neR7uYzxhmEDB8wOcW7zFe97SyO3bs6JohUMJteV+ZJYYrcu3eitrw/K6vvPKK61Aoh51yGVK+4YYbXL/99tuuGTLg/j/xiU+4fuGFF1x/61vfCo5VIQMhhBBCtDmaEAghhBAic0MGLAbRvXt31yz0QEuOIYOQVcdCHly5S7uNBUFEcmin0bZ8+eWXXY8bN+6Q+/niF7/oetOmTUnfw/2nS76uphatRygbINX1uWjRItcMLTA7itvTHqa9zLBCaD8cH63vlStXuh4+fLhrht/ymfPPP981f0OYZVBTU+N64cKFSffDMBDPKc8XQ98ME5C4C0bJIRBCCCGEJgRCCCGEyOCQAfsLcJUtX+dqThYjYsGO0Cp17pO2TtyWTTYQ6lnAFbVf//rXk74nZL2ecsoprjdu3Oh60KBBrtOtxa4wgWhpQj01vve977lmzxUzs/3797suLCx0zeuY1yqLEb3zzjtJ38P98HlGm5ohhrFjx7pm6HXEiBEJY42OPdvhMz167g4cOOD6ggsucM3jHMpO43Mq9JxhMTzCZ9+VV17pesGCBa6jz7W27j8hh0AIIYQQmhAIIYQQIoNDBgwHMARAQmEFZhPs3LnTNe1n2nPMLGD2gfg/XLkfsk9prZWWlh5yP6Rv376uq6urXR9JyECI1mTw4MGu//a3v7lmtpJZ4nMrdP+wnS7DAV/+8pddMzSwfPly142Nja65gp37Z/E2hjCeeeaZhLEytHDppZdathMKa5qZ3XPPPa5DRekYgglls/F3hiFrvs5teR75jLvxxhtdP/300wljVWEiIYQQQrQ5mhAIIYQQInNDBrRaWIyI9j4tGNaS3rp1q+uBAwe6jlp6zdCWod0j/g/telqSf/7zn133798/6bZc9RwqiDJq1CjX7GVAQkVgUnXwVsaBaAlYKI19Vnr37u2a17lZ+Lqkdd+rVy/XlZWVrhlCo73PVvAsusb7MFS8jfdehw4dEsbEz86FkEEqWHSI7YmZmcDnXajQWaiPBd9PzX0ylMPrKW7kEAghhBBCEwIhhBBCZHDIgKv9aeOzqARXtTMrge12WSSChSFYYIIWeMj2zndC9udbb73lOnTsaLNRh4oUUfO8chV2qAWzSA2PG89paDXzjBkzXF9zzTWu2RI2H7I/1q5dm/R1rjqPhqd4XTKriUVvLr/88qT7nTt3ruvf/e53rpm9c95557nmc27Pnj2u2RMhZImbfTzckUtEvyuLPoUK1IWeWXxPOscstC0/d9euXa7ZNt7MrE+fPof8jJZET1IhhBBCaEIghBBCCE0IhBBCCGEZvIaAlZ8YR+a6AcbNGJN57LHHXLPiF+MxjO0wDYgVv8T/CcXpmcJz8cUXJ30P48qMW4fSdnr27On6j3/8o+srrrgi6bZaQ5A+6RwrxssZf43GYpvJh9TOurq6pK+nquAZih/zOma69N133+26R48erk8//XTXrM7K5xbTCBmT5vOM7+faAjOzd99913KVNWvWJPzd0NDgmuvTuKaJKc78zSF8roXW5oTWIhD+1v36179O+Le77ror6TathZ6kQgghhNCEQAghhBAZHDJgOg9tTmqm17AxxfDhw10zNSQUGuB7ysrKjmbYOUM0zTCUTkarkmmBJGRTh/bJXu2LFi1K+p58sKmPhlBKJ9NElyxZ4pr30vz5813/9Kc/dR1KgTracxFKac2kc8wmRLTt+RxJNV5+x27durn+6le/6pqNi0KfTXuZlVd3797tOtR8jGOI3pNMi6SlHq1omI2wAZVZ4r0RCkF379496b4YNmNYgftk+IDVIXn8+bl8Dq5YsSLh8xQyEEIIIUSbowmBEEIIITI3ZEBLi+EDVhikxcMqaoRVwbgfWja0eAYNGnSEI84tohkAtLU2b97smseXpFO9LvQ6q+Cxp3w62+YzoQZUbJ5y//33uz7nnHNcv/baa655bKdNm+b61ltvdc2wXGg1fbphp0wKDYRgNgCfTakaa/HfaC+HjhfP02mnnZb0PYQNwRjmCTXUSZWZw7DpG2+84ZrVELOVVCGDLl26uGZ1XGZPsRERjyfPY+g64DGnDoXEGdKLAzkEQgghhNCEQAghhBAZHDKgfUM7i3YPbZphw4Yl3U/Xrl1d07LhqlpaNuyPLZKzbNky1xdeeGGL7DNUzKOxsdH1X/7yF9cDBw50zWvCLLzKOheIFgcKFcbZsmWL65deesk1e92zKMsZZ5zhmivnV69e7Xry5MmuGT646qqrXOdqkaja2lrXPG6pGgax+A+zALiKf+vWra6fffZZ19ddd51rZoCwUBft/FCRHJIqnENoW+dCyGD79u0Jf4cKpTFLKtT4i6HmUNGh0LEN7ZP3LUMVcZCbd68QQgghDgtNCIQQQgiRuSEDZhPQEmZfA8JVz4RFQLiyk4QstnwgZG+lWsVPa3Tw4MGHvX0yQivNv/GNb7j+1a9+5Zohg2iIIBR+yHQ4bl7z/A6pwiGsR//II4+4vummm1z//ve/dz127FjXPLbMHOEK7X79+rlmQR2e686dO7teuXJlwvi4ep0Fdpqamlwz5BAqShUHDDGy2AyJ3ks8b/xeDBmce+65rm+//XbXLJBGG5njYCiBzzZeIzzOBw4ccM2sBzOzvXv3umYvhFyAYRmzxO/OYnUMTzJkHcosYCg7RCiswPPF64nXhlliqKqoqOiQn3e0yCEQQgghhCYEQgghhMjgkAEL0tBqia4ob4aFPAhDD7TYaHPSzou2Bc11GC7hMWGRFDOzqVOnuuYx/dKXvuT6vvvucz106NAWGROtb65+njt3ruvFixcnbB9a8Zvp4QOOL2RLR1m/fr3rG2+80fXo0aNdMwOHbXV5vmpqalyzLwgtVV4TfA9bjLOIS/Q70KqlJcvMntLSUstEaLeHChOFnk1miXbvn/70J9c8N2zT+9e//tU178vQqn9a/iy2w/PH4x/NiOC5Yq+GXCD6LGMYmeeVoRae19AzJNQOnPvh8T///PNdv/rqq64Z1oneMwoZCCGEEKLN0YRACCGEEJkbMmBBIdqLdXV1rhkmoDXDtqDUXD1LG477zzdChWSiK7x5fKlZqGPmzJmuV61a5Zr9IXheN23a5JordmnpcVU1bWqGdhYuXJgwVtrl2QoLArEt7rZt2xLex34ezPj48Y9/7JrFiHjcXn/9dddss/rcc88FP68ZnguGkGh58joxS7RG0yn8EmrhHAdcFR5qexuF35fjZ+YGw5i0r3mfsP0xe06w2BGPO8fKjBH2roje3wzb5FqWQa9evRL+5vFhhguPYSjsGAofhPpHhMLdvIb4jIuGNXnumXnSWsghEEIIIYQmBEIIIYTI4JDBmWee6ZrWI204tiRlaICcfvrprmm3cSV7aNt8ILTynqvXzRJtYa585fa0OYcMGeKalt03v/lN15MmTXIdCuHQWuO5p1UeLTxC4sws4DVGu5DflZo113/+85+7pq0Ztc5pOdPqZX8B9iD4wx/+4Lp3796uH330Ude07UMFwvgehp327dvnunv37gljZSiHn82CR3379nUdd5iA0BKmtcxiUFOmTEnYZsGCBa6ZBVBcXOz6iSeecD1mzBjXtPfXrl3rmn0p+FxkdgezBHj98/qKFg5j/wqONVuh1c6+HmaJ4S5mtfBY8frm8yidUAJhiG7nzp2uQ+couh9uc9FFFyX9jJZEDoEQQgghNCEQQgghRAaHDGi30hrjClHWTQ9By5n75H7U8vjjRFca02JkzW/a+NyGx5r22IMPPuialjDtaIYkuJ9Qbfif/exnCWPlivk44RijteOTweuc1j4LmkSt3vHjx7tmfwdazhMnTnT9y1/+0jWzdPg6VzOztjo/m+eCYQW+P2o9V1RUWLaSTuiJoR2zxOJqXEnO9slckT5nzhzXzLTh/cZzwOcWMxQY0qBlzUye6PfhOKL19LMRWu2hAkJmZv3793f9yiuvuA7dr7T00+mBw2dAKCOF+4xmfYX677QWcgiEEEIIoQmBEEIIITI4ZEArmtYM7ZXCwsJD7oerRalD7ULzGa5gjtqGXBlN+zNUfIWWZ0lJiWtam7Qw+Xlc1RtqMRoKN5iZrVu3zjWzHdoaFtFiESCu6GY2Da9PrixnJgHtY7PEokWh9qqsi08bnwWIvv/977umXRqymXkfcp887xs2bEgY62233eZ61qxZrvm9eX3Q7o67x0g69nA0q4Kr2Tdu3Og6VDOfWTo8f7wfQoXEeHxCBaBYuKq6ujphe2Za8RxkK2wZHX0+8FjxmmaGDMNg6Zx7wveHzhfDRjxfh9s2vqWRQyCEEEIITQiEEEIIkcEhA66UpZXToUMH17SGQ9DypDVDGy5umyZTWLJkieuo1UUbjLq8vNw1wwq0gWkp046mpo0eKoDD99fX17uOWpy0v5955hmLiyeffNL1Qw895PpTn/qUa1q1rDvP/g+0j7ly3Swx1MLV1FyBfsYZZ7hmIZ177rnHNUMXzN4J2ce8rzhujvXss89O2IbXFzMZuH0ou2jkyJGu2TMjDkLPCz6bzBKfYaHCNbSs+d1DrYpD9jXvGe6TIaZx48a5/slPfpKwfaoQXDbC34xoxgCP4dKlS13znkmVmZBsPyHSKUgWKnqV7jhaEjkEQgghhNCEQAghhBAZHDJg0RTalrRM+/Tp4zrUKjVUT55FRFSY6H+wJ0D0mNAKpr3PngKsH06ri++hRc5sBdZiZ7iCIYOQPR5dgb5ixQrLBL7yla+45rF94403XLO+PO1dFnNKtdqex4p2I69vWqYseES7lCE0jo/H/2iJtqFtJmSVM2OBBWTiIFW9+WaibdR5DkKZUuRwi96ksx/eJwwLRQmFHLIVHj9me5iFw5ChVsXpHI9QW2TenzwX/I3iGKJhJz4H2gI5BEIIIYTQhEAIIYQQGRwyoGVNu5qatg7tVhYsopXDldG0jWiB5zO0illMyCxxxTftuJqaGte0rGmD0Tbj+aOFxqwBno9QYQ+GkaKWXlvbbCHY1je6qrsZ9m1g/XWGGFjUKFowisctVOCE9iRtbdqTvN8YluO9xOwDbhsK0UVXd7PYC68VFmnhZ/D1uEnH8i8qKkr4m6GydLIG0glLkJCVzX3ymRcdX2hf6fTdyHR2797tOvoM4d+8dnleDjdMkM75CsHPioYE+XxtC+QQCCGEEEITAiGEEEJkcMiAhFpI0n7esWOHa9qcDA2EMg6iKzvzCa5yj7ZvJTyOITuNYYWQfR1qzcrzwfPEMfF887Oidl0o86FLly5Jxx0ntHGp4+zBID4OrfeQPcysJzOzt99+23WoSFE6de9J6N7jtkdiX3McudDbhUXr2NfALLFQ1+GGaQ6XUGGh0POUYVuzxEybtkAOgRBCCCE0IRBCCCGEJgRCCCGEsCxZQ8DqdoxNE6Zpse83YzWMZTMenc9rCBizSpVuFEqx4flgLIwxU8bRGPvn53E9AfdfV1fnOpRymqo51W9/+1vX1113XfB9QqQinQZopaWlCX9zLQtTOUNV7ULrCULrBrif0P3A+43rcaJNdPjZoYZW2cTixYuD/3bfffe5fv75512HmnqF1hnwGHKNCeG21Hxu8jnYGusYDgc5BEIIIYTQhEAIIYQQWRIyKC4udr1t2zbXtFeY4kNSVbRrJp+bG7311ltJX4/2RA81W0mnkQdhQyNaqqGKYXw/958qXYvXS3V1tWuFDMSRQns4ncZDZonhylBjm3QaFFGnE0pgyIBjYIpxqmce78tcZOPGja55rA63OiS3TSd9MdQwiRVK40YOgRBCCCE0IRBCCCFEloQM2M96y5YtrkPNjQhfD1UqZBZDvsFGQLS6oiuNQxZmaBUtj3Uoy4A2LFfd0uYMVU1LZe/x86I96oU4EkJ2byoYuuJ1n47tT0J2dOje4/579+7tmvdV9P5J1ZQq1wit8GcWU4jQbwgJhU5D4Qb+vjGryiwx86EtkEMghBBCCE0IhBBCCJElIQM2o1i6dKlr2snsf01oA4Vs77a2ZTIJNs8INYIyS7T3aZXxONIGo1XG99BGZbiCn8ciRaExpbNSO/p5QhwpvOZpCZeUlAS3YdGvE0880TXDWEdTiIb3Qyj0QHt87dq1rnv27Jnwvn379rlmEaVchN+Vxz+U6cTnWugZFyrExpBE6PnFBmwvv/xywlivuuqqVF+lxZFDIIQQQghNCIQQQgiRJSGDHj16uKbNTBtv165dSbflqs36+nrXrOsdWi2aDxQVFblmkSK+bpYYeqHdRQst1DOevSI+/elPu16zZo1r2mYMGYSyFVL1MmD46NJLLzUhjpZRo0a5nj17tutU4caqqirXtOt5ffO+qqmpcc1QGUMU3Jahh8LCQtfdu3d3ffbZZ7u+/vrrXT/++OMJY+Wz8eqrr072dXIG2vs8zsxI47PmnXfeSbqfdApU8beLzymex6FDh7ru27fvIffZmsghEEIIIYQmBEIIIYTIkpDBDTfc4Jr1uLmCc/LkyUm3nTJliutZs2a5pn1z7bXXtsg4sxFaoZ/97Gddt2/fPuF9tNYYbqG1Rs3319bWumZbUn4GQxRcMc3wBK3TVAVFGD7q37+/CXG0DBkyxHW/fv1ch9remplNmjSpVcd0NDDEYGZWVlbmOlXmRLYQKuBkZrZu3TrXDD0yK+TVV191zZABMxS4X4Zv+Gxi0aFevXq55vGOhmfT/R6tgRwCIYQQQmhCIIQQQgizgoNHUxlDCCGEEDmBHAIhhBBCaEIghBBCCE0IhBBCCGGaEAghhBDCNCEQQgghhGlCIIQQQgjThEAIIYQQpgmBEEIIIUwTAiGEEEKY2X8BNqNjg6j2eGgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.title(str(y[i].numpy()))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: *Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:46:06.212842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-14 20:46:06.213281: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "standardization = tf.keras.layers.Normalization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(\n",
    "    list(sample_image_batches.as_numpy_iterator()), axis=0\n",
    ").astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        standardization,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:46:06.566217: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-03-14 20:46:06.566243: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-03-14 20:46:06.567097: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-03-14 20:46:06.592421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-14 20:46:06.592760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     79/Unknown - 1s 3ms/step - loss: 0.8373 - accuracy: 0.7128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:46:07.187981: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-03-14 20:46:07.188007: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-03-14 20:46:07.191174: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-03-14 20:46:07.192534: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-03-14 20:46:07.192798: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: my_logs/run/20240314_204606/plugins/profile/2024_03_14_20_46_07/laptop-of-tan.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1709/Unknown - 5s 2ms/step - loss: 0.4449 - accuracy: 0.8422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:46:11.469262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-14 20:46:11.469894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4450 - accuracy: 0.8422 - val_loss: 0.3752 - val_accuracy: 0.8680\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3393 - accuracy: 0.8769 - val_loss: 0.3626 - val_accuracy: 0.8744\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3003 - accuracy: 0.8899 - val_loss: 0.3305 - val_accuracy: 0.8832\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2753 - accuracy: 0.8974 - val_loss: 0.3355 - val_accuracy: 0.8834\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2582 - accuracy: 0.9031 - val_loss: 0.3242 - val_accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x72d026ec4cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logs = Path() / \"my_logs\" / \"run\" / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10\n",
    ")\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-26e45b20992fddae\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-26e45b20992fddae\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handsonds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
