{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "twzBxqEHPI5n"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaVXlmm5PI5p"
      },
      "source": [
        "Exercise: *Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_dsvG_TPI5q",
        "outputId": "b66b7103-b1ee-4291-b649-68375edf7c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZlZ7MgSPI5r"
      },
      "source": [
        "- The author uses a model with 2 convolutional layers, a max pooling layer, then dropout 25%, dense layer, another dropout but with 50%, and the output layer.\n",
        "- This model reaches about accuracy in the test set.\n",
        "- This placed the model roughly in the top 20% of the [MNIST Kaggle competition](https://www.kaggle.com/c/digit-recognizer/).\n",
        "- You should ignore the models with an accuracy greater than 99.79%, which were most likely trained on the test set, as explained by Chris Deotte in [this post](https://www.kaggle.com/c/digit-recognizer/discussion/61480)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTZYxIstPI5s",
        "outputId": "ad7134fd-450e-4b87-d2cf-3b73696efe0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 22s 7ms/step - loss: 0.1871 - accuracy: 0.9425 - val_loss: 0.0512 - val_accuracy: 0.9848\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0809 - accuracy: 0.9755 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0385 - val_accuracy: 0.9890\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0485 - accuracy: 0.9849 - val_loss: 0.0408 - val_accuracy: 0.9886\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0395 - val_accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0419 - val_accuracy: 0.9898\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0371 - val_accuracy: 0.9918\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0408 - val_accuracy: 0.9902\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0383 - val_accuracy: 0.9914\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9914\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.03281183913350105, 0.9914000034332275]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is the author's model\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32,\n",
        "            kernel_size=3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            kernel_initializer=\"he_normal\",\n",
        "        ),\n",
        "        tf.keras.layers.Conv2D(\n",
        "            64,\n",
        "            kernel_size=3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            kernel_initializer=\"he_normal\",\n",
        "        ),\n",
        "        tf.keras.layers.MaxPool2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10)\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsa2d_9ePI5s"
      },
      "source": [
        "According to the same post (link above), we can achieve a higher accuracy (99.5 to 99.7% on the test set), you need to add image augmentation, batch norm, use a learning rate schedule such as 1-cycle, and possibly create an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwUUXOdUPI5t",
        "outputId": "70f3a753-f7ae-4ab6-dfe3-d44c8f8e2372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 15s 7ms/step - loss: 0.1611 - accuracy: 0.9531 - val_loss: 0.0480 - val_accuracy: 0.9892\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0757 - accuracy: 0.9773 - val_loss: 0.0405 - val_accuracy: 0.9886\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0340 - val_accuracy: 0.9908\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.0320 - val_accuracy: 0.9908\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.0337 - val_accuracy: 0.9902\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.0355 - val_accuracy: 0.9898\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.0332 - val_accuracy: 0.9922\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0352 - val_accuracy: 0.9914\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0316 - val_accuracy: 0.9922\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9915\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.03181219473481178, 0.9915000200271606]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is my model\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32,\n",
        "            kernel_size=3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            kernel_initializer=\"he_normal\",\n",
        "        ),\n",
        "        tf.keras.layers.Conv2D(\n",
        "            64,\n",
        "            kernel_size=3,\n",
        "            padding=\"same\",\n",
        "            activation=\"relu\",\n",
        "            kernel_initializer=\"he_normal\",\n",
        "        ),\n",
        "        tf.keras.layers.MaxPool2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10)\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is trained on Colab, as it take minutes to train on a CPU."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
