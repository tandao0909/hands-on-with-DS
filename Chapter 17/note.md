Autoencoders are auto-encoders, which means they learn about the internal structure of the dataset, without the label. More technically, they can learn about the dense representations if the dataset, which is called *latent representations* or *codings*, without any supervision. These codings typically have much lower dimensionality than the original one (in some sense, they are similar to embeddings). Therefore, they are useful for dimensionality reduction, especially for data visualization tasks (see chapter 8). They can act as *feature detectors*, and can be used in unsupervised pretraining step in deep neural networks (see chapter 11). Finally, some autoencoders are generative models, which means we can ask them to generate new data that are similar to the training data. For example, you can train an autoencoder on a dataset of faces, and it would generate some very convincing faces for you.

*Generate adversarial networks* (GANs) are also deep neural networks capable of generating new data. In fact, they can create pictures of faces so convincing that it's hard to tell the person is actually not real. You can checkout yourself at https://thispersondoesnotexist.com, a website that generate fake faces using a GAN architecture named StyleGAN. You can also checkout the list of non-existent Airbnb listings at https://thisrentaldoesnotexist.com. GANs are now widely used in super resolution (increasing the resolution of an image), colorization, image editing (e.g., replace backgrounds of an image), augmenting data (for training another model), predicting the next frames in a video, generating other type of data (mostly sequence, such as text, video, audio, time series), identifying the weaknesses of other models.

Another competitor has joined recently is *diffusion models*. In 2021, they managed to generate more diverse and higher-quality than GANs, while being much easier to train and has become the norm. However, diffusion models are much slower to run.

Autoencoders, GANs, and diffusions models are all unsupervised models, capable of learning latent representations, and can be used to generate new data. However, the way they work are very different:
- Autoencoders: They simply learn to copy its input to its output. However, it's not so trivial that the model can just pass the data all the way to the last layer. As you will see, we will add lots of constraints to the model in training. For example, we can add some noises and train it to recover the original input, or limit the size of the latent representations. These constraints restrict the model from trivially copy the input to the output, force them to represent data efficiently. In short, the codings are byproduct of the autoencoder trying to learn the identity function under some constraints.
- GANs are composed of two deep neural networks: One is a *discriminator*, trying to find which data is counterfeit data, while the other is a *generator*, trying to create more and more convincing fake data. This architecture is very original in deep learning in that the generator are the discriminator compete between each other: You can think of the generator is the criminal trying to create fake money, while the discriminator is the police trying to tell which money is fake. *Adversarial learning* (training competing neural networks) is considered one of the most important innovations in 2010s. In fact, Yann LeCun even said that it was "the most interesting idea in the last 10 years in machine learning" in 2016.
- A *denoising diffusion probabilistic model* (DDPM): is trained to remove a tiny bit of noise form an image. If you feed it an image full of Gaussian noise and repeatedly run the diffusion model on that image, a high-quality image will slowly emerge, similar to the training images, but not identical.
